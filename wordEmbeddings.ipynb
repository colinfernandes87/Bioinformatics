{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wordEmbeddings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colinfernandes87/Bioinformatics/blob/master/wordEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NSy4xreBoKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries to build Word2Vec model, and load Newsgroups data\n",
        "import os\n",
        "import re\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.phrases import Phraser, Phrases\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "#from pprint import pprint\n",
        "#pprint(list(newsgroups_train.target_names))\n",
        "cats = ['alt.atheism']\n",
        "newsgroups = fetch_20newsgroups(subset='all', categories=cats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJa9hTRfdGBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DaAeu7fh_Ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cleaning data - remove punctuation from every newsgroup text\n",
        "sentences = []\n",
        "texts=newsgroups.data\n",
        "# Go through each text in turn\n",
        "for ii in range(len(texts)):\n",
        "    sentences = [re.sub(pattern=r'[\\!\"#$%&\\*+,-./:;<=>?@^_`()|~=]', \n",
        "                        repl='', \n",
        "                        string=x\n",
        "                       ).strip().split(' ') for x in texts[ii].split('\\n') \n",
        "                      if not x.endswith('writes:')]\n",
        "    sentences = [x for x in sentences if x != ['']]\n",
        "    texts[ii] = sentences\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh04Zt7KDOW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenate all sentences from all texts into a single list of sentences\n",
        "all_sentences = []\n",
        "for text in texts:\n",
        "    all_sentences += text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVwXFqjsE6KM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Phrase Detection\n",
        "# Give some common terms that can be ignored in phrase detection\n",
        "# For example, 'state_of_affairs' will be detected because 'of' is provided here: \n",
        "common_terms = [\"of\", \"with\", \"without\", \"and\", \"or\", \"the\", \"a\"]\n",
        "# Create the relevant phrases from the list of sentences:\n",
        "phrases = Phrases(all_sentences, common_terms=common_terms)\n",
        "# The Phraser object is used from now on to transform sentences\n",
        "bigram = Phraser(phrases)\n",
        "# Applying the Phraser to transform our sentences is simply\n",
        "all_sentences = list(bigram[all_sentences])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7zzAVvHFQss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Word2Vec(all_sentences, \n",
        "                 min_count=3,   # Ignore words that appear less than this\n",
        "                 size=200,      # Dimensionality of word embeddings\n",
        "                 workers=2,     # Number of processors (parallelisation)\n",
        "                 window=5,      # Context window for words during training\n",
        "                 iter=30)       # Number of epochs training over corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu3ZYodkFXtL",
        "colab_type": "code",
        "outputId": "621f76ea-a052-47ad-bff9-3863296e7365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "\n",
        "model.most_similar('atheism')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('theism', 0.7576792240142822),\n",
              " ('predictions', 0.6784950494766235),\n",
              " ('definition', 0.6374922394752502),\n",
              " ('viewpoint', 0.6100046038627625),\n",
              " ('homosexuality', 0.6088317632675171),\n",
              " ('faith', 0.6081131100654602),\n",
              " ('ignorance', 0.6039700508117676),\n",
              " ('necessarily', 0.6035125255584717),\n",
              " ('religion', 0.5991615056991577),\n",
              " ('matter', 0.5958645939826965)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LssbaL_OMtI-",
        "colab_type": "code",
        "outputId": "b9890563-2a85-4fb4-edf7-5ec230583a8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
        "import pandas as pd\n",
        "\n",
        "cv=CountVectorizer(max_df=0.85,stop_words='english',max_features=10000)\n",
        "word_count_vector=cv.fit_transform(newsgroups.data)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(newsgroups.data)\n",
        "vectors.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(799, 15619)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrilA21y2BDy",
        "colab_type": "code",
        "outputId": "c763ae14-b16c-4398-a20c-df560232b929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(word_count_vector)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TjXaoCx2o-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# you only needs to do this once, this is a mapping of index to \n",
        "feature_names=cv.get_feature_names()\n",
        " \n",
        "# get the document that we want to extract keywords from\n",
        "doc=newsgroups.data[1]\n",
        "\n",
        "#generate tf-idf for the given document\n",
        "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
        "\n",
        "#sort the tf-idf vectors by descending order of scores\n",
        "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        " \n",
        "#extract only the top n; n here is 10\n",
        "keywords=extract_topn_from_vector(feature_names,sorted_items,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUXpuYff3SRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sort_coo(coo_matrix):\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        " \n",
        "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
        "    \n",
        "    #use only topn items from vector\n",
        "    sorted_items = sorted_items[:topn]\n",
        " \n",
        "    score_vals = []\n",
        "    feature_vals = []\n",
        "    \n",
        "    # word index and corresponding tf-idf score\n",
        "    for idx, score in sorted_items:\n",
        "        \n",
        "        #keep track of feature name and its corresponding score\n",
        "        score_vals.append(round(score, 3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        " \n",
        "    #create a tuples of feature,score\n",
        "    #results = zip(feature_vals,score_vals)\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]=score_vals[idx]\n",
        "    \n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jflF-e4o2vch",
        "colab_type": "code",
        "outputId": "1a886041-ca26-43c1-f3ce-e82d14d87e42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "print(\"\\n===Keywords===\")\n",
        "for k in keywords:\n",
        "    print(k,keywords[k])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===Keywords===\n",
            "bcci 0.36\n",
            "islamic 0.248\n",
            "references 0.207\n",
            "gregg 0.203\n",
            "banking 0.155\n",
            "slander 0.152\n",
            "mathew 0.148\n",
            "piece 0.138\n",
            "knows 0.134\n",
            "title 0.127\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}